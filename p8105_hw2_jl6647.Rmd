---
title: "p8105_hw2_jl6647"
author: "Jiatong Li"
date: "2023-09-27"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(readxl)
library(dplyr)
```

### HW2 Problem 1

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv("fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r range(pols$year)[1]` to `r range(pols$year)[2]`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r range(snp$year)[1]` to `r range(snp$year)[2]`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.


## HW2 Problem 2

### Read and clean Mr. Trash Wheel's data

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
* use reasonable variable names 
* omit rows that do not include dumpster-specific data

### Mr. Trash Wheel
```{r}
trash_df = read_excel(
  "202207 Trash Wheel Collection Data.xlsx",
  range = "A2:N549",
  sheet = "Mr. Trash Wheel"
) |> 
  janitor::clean_names() |>
  mutate(year = as.integer(year)) |> 
  mutate(homes_powered = weight_tons*500/30) |> 
  mutate(wheel_type = "mr") |> 
  drop_na(dumpster)

```
### Professor Trash Wheel
```{r}
professor_df = read_excel(
  "202207 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",
  range = "A2:M96"
) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30) |> 
  mutate(wheel_type = "professor")
```
### Gwynnda Trash Wheel
```{r}
gwynnda_df = read_excel(
  "202207 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = "A2:K109"
) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30) |> 
  mutate(wheel_type = "gwynnda")
```

### Combine datasets together

```{r}
combined_dataset = bind_rows(trash_df,professor_df,gwynnda_df) |> 
                   relocate(wheel_type)
print(combined_dataset)
```

### Describe the data

* Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in July of 2021?


The number of observations in the combined dataset: `r nrow(combined_dataset)`

The number of variables in the combined dataset: `r ncol(combined_dataset)`

Names of key variables: `r names(combined_dataset)`

Total weight of trash collected by Professor Trash Wheel: `r sum(professor_df$weight_tons)`

Total number of cigarette butts collected by Gwynnda in July of 2021: `r sum(gwynnda_df$cigarette_butts[which(gwynnda_df$month == "July" & gwynnda_df$year == 2021)])`

## HW2 Problem 3

### Import, clean, and tidy the dataset of baseline demographics

* Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric)
* Remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline)

```{r}
baseline_df = 
  read_csv("data_mci/MCI_baseline.csv",skip = 1) |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "Male",
      0 ~ "Female"),
    sex = as.factor(sex)) |> 
  mutate(
    apoe4 = case_match(
      apoe4,
      1 ~ "APOE4 Carrier",
      0 ~ "APOE4 Non-carrier"),
    apoe4 = as.factor(apoe4)) 
  
mci_baseline = 
  baseline_df |> 
  filter(age_at_onset != ".")
      
```
### Discuss important steps in the import process and relevant features of the dataset

* How many participants were recruited, and of these how many develop MCI? 

`r nrow(baseline_df)` participants were recruited.

`r nrow(mci_baseline)` develop MCI.

* What is the average baseline age?
```{r,echo=FALSE}
baseline_age =
  mci_baseline |> 
  summarise(mean_age = mean(current_age, na.rm = TRUE)) |> 
  pull(mean_age)
```
The average baseline age is `r baseline_age`

* What proportion of women in the study are APOE4 carriers?
```{r}
carrier_female = 
  mci_baseline |> 
  filter(sex == "Female" & apoe4 == "APOE4 Carrier") |> 
  count()
```
In the study, `r carrier_female/nrow(mci_baseline)` is the proportion of women in the study are APOE4 carriers

### Import, clean, and tidy the dataset of longitudinally observed biomarker values
```{r,echo=FALSE}
amy_df = 
  read_csv("data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |> 
  subset(
   baseline!="NA" & baseline!="Na"
  )|>
  rename(
  id=study_id,
  Time_2_years=time_2,
  Time_4_years=time_4,
  Time_6_years=time_6,
  Time_8_years=time_8
  )
```
```{r}
amy_df
```

### Comment on the steps on the import process and the features of the dataset

During the import process, data is imported from `mci_amyloid.csv` and participants who have no MCI is removed from baseline column to avoid invalid data. Variable names have been changed to make the data more understandable. To better combine the two datasets of mci_amyloid and mci_baseline, 'study_id' is changed.

`r nrow(read_csv("data_mci/mci_amyloid.csv",skip = 1))` participants were recruited.

`r nrow(amy_df)` participants observed biomarker values.

In the study, `r nrow(amy_df |> subset(Time_2_years!="NA"&Time_4_years!="NA"&Time_6_years!="NA"&Time_8_years!="NA"))/nrow(amy_df) ` is the proportion of participants who successfully completed the whole process.

### Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings
```{r,echo=FALSE}
left_join_dfs =
  left_join(mci_baseline,amy_df, by = "id")

only_in_baseline_df=
  left_join_dfs|>
  subset(
    is.na(left_join_dfs$baseline))
```
There're `r nrow(only_in_baseline_df)` participants appear in only the baseline datasets. 
```{r}
only_in_baseline_df
```
```{r,echo=FALSE}
right_join_dfs =
  right_join(mci_baseline,amy_df, by = "id")

only_in_amy_df=
  right_join_dfs|>
  subset(
    is.na(right_join_dfs$age_at_onset))
```
There are `r nrow(only_in_amy_df)` participants appear in only the amyloid datasets.
```{r}
only_in_amy_df
```
### Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset

```{r,echo=FALSE}
both_have_df =
  inner_join(mci_baseline,amy_df,by="id")
whole_process_df =  
  both_have_df |> 
  na.omit(both_have_df)
```
As seen in the datasets below, after combination, `r nrow(both_have_df)` participants appear in both two datasets, and only `r nrow(whole_process_df)` participants successfully went through the whole process.
```{r}
both_have_df
whole_process_df
```
### Export the result as a CSV to your data directory
```{r}
write_csv(both_have_df,"Participants appear in both mci_amyloid and mci_baseline datasets")
write_csv(whole_process_df,"Participants appear in both datasets and went through the whole process")
```


